{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26d42764-1b1f-49a7-abeb-dc36a9767e7c",
   "metadata": {},
   "source": [
    "## This module helps to generate Model weights to be used later without overhead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a68ec86-9830-4675-aa0c-fdb1d85dcd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter & ignore warnings for clear output visualization\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16d449eb-fa7f-4da0-97fb-cca440a19782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary packages\n",
    "\n",
    "import os\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from statistics import mean\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9926f77d-141d-4efc-8274-8a1071c861af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain file paths\n",
    "current_directory = os.getcwd()\n",
    "current_directory = current_directory.replace(\"/Single-Use-Code\", \"\")\n",
    "data_path = current_directory + \"/Datasets-CSV\"\n",
    "sav_path = current_directory + \"/Model-Weights/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5470cd4-1e80-4524-9971-d334219658a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets for all possible combinations & for individual disease's respective symptoms\n",
    "\n",
    "df_combination = pd.read_csv(data_path + \"/Disease_Symptom_Dataset_For_All_Symptom_Subsets.csv\") \n",
    "df_independent = pd.read_csv(data_path + \"/Disease_Symptom_Dataset_For_Respective_Symptoms.csv\") \n",
    "\n",
    "X_combination = df_combination.iloc[:, 1:]\n",
    "Y_combination = df_combination.iloc[:, 0:1]\n",
    "\n",
    "X_independent = df_independent.iloc[:, 1:]\n",
    "Y_independent = df_independent.iloc[:, 0:1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4dd12f0f-019b-4bae-8b51-1398a739a8f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing with Logistic Regression...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/Users/Manasa/Downloads/Performing-Symptom-Analysis-using-Big-Data-Management-Expert-Systems-to-Detect-Potential-Diseases/Model-Weights/log_reg_cv.sav']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Logistic Regression Classifier & fit the data to it\n",
    "print(\"Processing with Logistic Regression...\")\n",
    "\n",
    "lr_classifier = LogisticRegression()\n",
    "lr_classifier = lr_classifier.fit(X_combination, Y_combination)\n",
    "filename = sav_path + \"log_reg.sav\"\n",
    "joblib.dump(lr_classifier, filename)\n",
    "\n",
    "lr_scores = cross_val_score(lr_classifier, X_combination, Y_combination, cv=10)\n",
    "lr_mean_score = mean(lr_scores)\n",
    "filename = sav_path + \"log_reg_cv.sav\"\n",
    "joblib.dump(lr_mean_score, filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31735079-c659-4631-968a-4a897d64ddd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing with Random Forest Classifier...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/Users/Manasa/Downloads/Performing-Symptom-Analysis-using-Big-Data-Management-Expert-Systems-to-Detect-Potential-Diseases/Model-Weights/rand_forest_cv.sav']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Random Forest Classifier & fit the data to it\n",
    "print(\"Processing with Random Forest Classifier...\")\n",
    "\n",
    "rf_classifier = RandomForestClassifier(n_estimators=10, criterion='entropy')\n",
    "rf_classifier = rf_classifier.fit(X_combination, Y_combination)\n",
    "filename = sav_path + \"rand_forest.sav\"\n",
    "joblib.dump(rf_classifier, filename)\n",
    "\n",
    "rf_scores = cross_val_score(rf_classifier, X_combination, Y_combination, cv=10)\n",
    "rf_mean_score = mean(rf_scores)\n",
    "filename = sav_path + \"rand_forest_cv.sav\"\n",
    "joblib.dump(rf_mean_score, filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e0d716a-8d42-4a49-aa80-3a34109cec7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing with KNN Classifier...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/Users/Manasa/Downloads/Performing-Symptom-Analysis-using-Big-Data-Management-Expert-Systems-to-Detect-Potential-Diseases/Model-Weights/knn_cv.sav']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create KNN Classifier & fit the data to it\n",
    "print(\"Processing with KNN Classifier...\")\n",
    "\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=10, weights='distance', n_jobs=4)\n",
    "knn_classifier = knn_classifier.fit(X_combination, Y_combination)\n",
    "filename = sav_path + \"knn.sav\"\n",
    "joblib.dump(knn_classifier, filename)\n",
    "\n",
    "knn_scores = cross_val_score(knn_classifier, X_combination, Y_combination, cv=10)\n",
    "knn_mean_score = mean(knn_scores)\n",
    "filename = sav_path + \"knn_cv.sav\"\n",
    "joblib.dump(knn_mean_score, filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "542e09fa-2053-4dbb-a3c0-797a89d5cb5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing with Multinomial Naive Bayes...\n",
      "Saved model weights successfully !!\n"
     ]
    }
   ],
   "source": [
    "# Create Multinomial Naive Bayes Classifier & fit the data to it\n",
    "print(\"Processing with Multinomial Naive Bayes...\")\n",
    "\n",
    "mnb_classifier = MultinomialNB()\n",
    "mnb_classifier = mnb_classifier.fit(X_combination, Y_combination)\n",
    "filename = sav_path + \"mnb.sav\"\n",
    "joblib.dump(mnb_classifier,filename)\n",
    "\n",
    "mnb_scores = cross_val_score(mnb_classifier, X_combination, Y_combination, cv=10)\n",
    "mnb_mean_score = mean(mnb_scores)\n",
    "filename = sav_path + \"mnb_cv.sav\"\n",
    "joblib.dump(mnb_mean_score, filename)\n",
    "\n",
    "print(\"Saved model weights successfully !!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
