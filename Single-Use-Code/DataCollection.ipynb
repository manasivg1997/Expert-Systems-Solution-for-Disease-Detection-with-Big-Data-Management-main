{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1aa8e51-d145-4504-a91f-7048c550a861",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e20e39f-1f1f-492a-b885-6432c5661c2b",
   "metadata": {},
   "source": [
    "## This module performs Web scraping to obtain list of Diseases & respective Symptoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8249caab-b507-494f-9c38-38298c246629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter & ignore warnings for clear output visualization\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b6089b0-b957-4abe-8666-60cb1f88f426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google in /Users/Manasa/opt/anaconda3/lib/python3.8/site-packages (3.0.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/Manasa/opt/anaconda3/lib/python3.8/site-packages (from google) (4.9.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/Manasa/opt/anaconda3/lib/python3.8/site-packages (from beautifulsoup4->google) (2.2.1)\n"
     ]
    }
   ],
   "source": [
    "# Install google module for python\n",
    "\n",
    "!pip install google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6dd1b700-4685-445b-a8e5-e00a30cacf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary packages\n",
    "\n",
    "import re\n",
    "import time\n",
    "import pickle\n",
    "import string\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from googlesearch import search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe3958e-a1ec-44dd-a2e4-6c26d7b8777d",
   "metadata": {},
   "source": [
    "### Functions to Obtain list of diseases from the website: www.nhp.gov.in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7d305d5-4e0f-4517-a06c-a0d6ccf38e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines a function to obtain diseases list from nhp\n",
    "\n",
    "def getDiseasesFromNhp():\n",
    "\n",
    "    # As diseases are ordered alphabetically in the website, we first maintain a list of lower case letters\n",
    "    lowercase_letters = list(string.ascii_lowercase)\n",
    "\n",
    "    # Read diseases from the website using the lowercase_letters list\n",
    "    diseases = []\n",
    "    base_url = \"https://www.nhp.gov.in/disease-a-z/\"\n",
    "\n",
    "    for letter in lowercase_letters:\n",
    "\n",
    "        # Track progress\n",
    "        print(\" --> Obtaining diseases that start with \" + letter)\n",
    "\n",
    "        # Form the target URL we are interested in\n",
    "        target_url = base_url + letter\n",
    "\n",
    "        # Add some sleep time to avoid affecting the performance of the web server as it can be problematic for us\n",
    "        time.sleep(1)\n",
    "\n",
    "        # Obtain target page without verifying certificate\n",
    "        target_page = requests.get(target_url, verify=False)\n",
    "\n",
    "        # Pull data from the HTML & XML pages by web scraping using BeautifulSoup\n",
    "        page_contents = BeautifulSoup(target_page.content, \"html5lib\")\n",
    "\n",
    "        # Retrieve all diseases from the page. We know the page structure by inspecting the html structure of the page on web\n",
    "        all_diseases = page_contents.find(\"div\", class_=\"all-disease\")\n",
    "\n",
    "        # Within the <div>(all-disease), we have a <ul> inside which we have several <a> which contain <li> with disease names\n",
    "        # So, from the obtained information, we perform futher processing to read the disease names\n",
    "        for tag in all_diseases.find_all(\"li\"):\n",
    "            diseases.append(tag.get_text().strip())\n",
    "\n",
    "        # Obtain set of diseases\n",
    "        diseases_set1 = set(diseases)\n",
    "        \n",
    "    return diseases_set1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97b379e3-e5c7-4e06-adf5-e02b05f770d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines a function to obtain diseases from pickle file\n",
    "\n",
    "def getDiseasesFromPickle():\n",
    "    # We obtain few other diseases too\n",
    "    other_diseases = None\n",
    "\n",
    "    # We use pickle to handle data serialization here\n",
    "    with open(\"other_diseases_pkl.txt\", \"rb\") as handle:\n",
    "        other_diseases = pickle.load(handle)\n",
    "\n",
    "    # Obtain set of diseases\n",
    "    diseases_set2 = set(other_diseases)\n",
    "        \n",
    "    return diseases_set2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "326f3e38-583c-45d7-b170-fcb9eb8d5ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines to a function to obtain final list of diseases\n",
    "\n",
    "def getFinalDiseases(diseases1, diseases2):\n",
    "    \n",
    "    all_diseases_list = list(diseases1.union(diseases2))\n",
    "    \n",
    "    # To make sure every diseases name starts with upper case so that sort order won't get effected\n",
    "    # We use capitalize() on each disease name\n",
    "    capitalized_diseases_list = []\n",
    "    \n",
    "    for disease in all_diseases_list:\n",
    "        capitalized_diseases_list.append(disease.capitalize())\n",
    "    \n",
    "    # Sort all the diseases for convenience\n",
    "    capitalized_diseases_list.sort()                \n",
    "\n",
    "    # Analysis of individual disease sets we obtained\n",
    "    len1 = len(diseases1)\n",
    "    len2 = len(diseases2)\n",
    "    len_common = len(diseases1.intersection(diseases2))\n",
    "\n",
    "    # Print analysis results\n",
    "    #print(\"Diseases1 length: \", len1, \" ---- Diseases2 length: \", len2, \" ---- Common diseases length: \", len_common)\n",
    "    print(\"Total diseases: \", len(capitalized_diseases_list))\n",
    "    \n",
    "    # print final list of diseases\n",
    "    #print(all_diseases_list)\n",
    "    \n",
    "    return capitalized_diseases_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76720b29-9e1e-415c-85bd-a3a26abbe326",
   "metadata": {},
   "source": [
    "### Functions to Obtain list of symptoms associated with symptoms from Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24eab334-136b-461b-a312-021f30775cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines a function to get symptoms for respective disease\n",
    "\n",
    "def getSymptomsFromWiki(all_diseases):\n",
    "    \n",
    "    # Final dictionary of symptoms\n",
    "    disease_symptoms = {}\n",
    "    count = 0\n",
    "    \n",
    "    for disease in all_diseases:\n",
    "        \n",
    "        count = count + 1\n",
    "        if count % 10 == 0:\n",
    "            print(\"Processed \", count, \" diseases\")\n",
    "        if count % 100 == 0:\n",
    "            print(\"-------------------------------------\")\n",
    "        \n",
    "        #print(\"Currently processing the disease: \" + disease)\n",
    "        \n",
    "        # Build search query\n",
    "        search_query = disease + \"wikipedia\"\n",
    "\n",
    "        # Search \"disease wikipedia\" on Google\n",
    "        for search_result in search(search_query, tld=\"co.in\", stop=10, pause=0.5):\n",
    "\n",
    "            # Open wikipedia link\n",
    "            match = re.search(r\"wikipedia\", search_result)\n",
    "\n",
    "            filled = 0\n",
    "\n",
    "            if match:\n",
    "                wiki_page = requests.get(search_result, verify=False)\n",
    "                wiki_contents = BeautifulSoup(wiki_page.content, \"html5lib\")\n",
    "                \n",
    "                #print(wiki_contents)\n",
    "\n",
    "                # Fetch HTML code for \"infobox\"\n",
    "                info_table = wiki_contents.find(\"table\", {\"class\":\"infobox\"})\n",
    "                #print(info_table)\n",
    "\n",
    "                if info_table is not None:\n",
    "          \n",
    "                    # Preprocess contents of infobox\n",
    "                    for row in info_table.find_all(\"tr\"):\n",
    "                        #print(row)\n",
    "                                 \n",
    "                        row_data = row.find(\"th\", {\"scope\":\"row\"})\n",
    "                        #print(row_data)\n",
    "                        #print(\"------------------\")\n",
    "                        \n",
    "                        if row_data is not None:\n",
    "                            row_data = row_data.get_text()\n",
    "                            #print(row_data)\n",
    "\n",
    "                            if row_data == \"Symptoms\":\n",
    "                                symptom = str(row.find(\"td\"))\n",
    "                \n",
    "                                symptom = symptom.replace(\".\", \"\")\n",
    "                                symptom = symptom.replace(\";\", \",\")\n",
    "\n",
    "                                # Remove bold text\n",
    "                                symptom=re.sub(r'<b.*?/b>:',',',symptom)\n",
    "\n",
    "                                # Remove hyperlink\n",
    "                                symptom=re.sub(r'<a.*?>','',symptom)\n",
    "                                symptom=re.sub(r'</a>','',symptom)\n",
    "\n",
    "                                # Remove all the tags\n",
    "                                symptom=re.sub(r'<[^<]+?>',', ',symptom)\n",
    "\n",
    "                                # Remove citation text\n",
    "                                symptom=re.sub(r'\\[.*\\]','',symptom)\n",
    "                                symptom=' '.join([x for x in symptom.split() if x != ','])\n",
    "\n",
    "                                # print(symptom)\n",
    "                                \n",
    "                                # Update symptoms\n",
    "                                disease_symptoms[disease] = symptom\n",
    "\n",
    "                                filled = 1\n",
    "                                break\n",
    "\n",
    "                if filled == 1:\n",
    "                    break\n",
    "                \n",
    "    return disease_symptoms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6604b587-8f10-4805-af95-171854884fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines a function that does preprocessing on the disease and associated symptoms list \n",
    "\n",
    "def saveSymptomsToPickle(disease_symptoms):\n",
    "    # Remove diseases that are associated with duplicate symptoms list\n",
    "    # print(len(disease_symptoms))\n",
    "    \n",
    "    temp_list = []\n",
    "    temp_dict = {}\n",
    "        \n",
    "    for key, val in disease_symptoms.items():\n",
    "        # Here, val is a list of symptoms associated with the disease\n",
    "        # So, we check if the same list already exists in the the temporary list we have\n",
    "        if val not in temp_list:\n",
    "            temp_dict[key] = val\n",
    "            temp_list.append(val)\n",
    "        \n",
    "    disease_symptoms = temp_dict\n",
    "    print(\"Total diseases considered after pre-processing: \", len(disease_symptoms))\n",
    "    \n",
    "    # Save the dictionary in a pickle file\n",
    "    with open(\"final_disease_symptoms.pickle\", \"wb\") as handle:\n",
    "        pickle.dump(disease_symptoms, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3fde86-6fc0-45e6-b6e0-5f5df8f06b3e",
   "metadata": {},
   "source": [
    "### Execution steps to Obtain diseases & the symptoms associated with them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29ac4441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------- OBTAINING LIST OF DISEASES ---------\n",
      "\n",
      " --> Obtaining diseases that start with a\n",
      " --> Obtaining diseases that start with b\n",
      " --> Obtaining diseases that start with c\n",
      " --> Obtaining diseases that start with d\n",
      " --> Obtaining diseases that start with e\n",
      " --> Obtaining diseases that start with f\n",
      " --> Obtaining diseases that start with g\n",
      " --> Obtaining diseases that start with h\n",
      " --> Obtaining diseases that start with i\n",
      " --> Obtaining diseases that start with j\n",
      " --> Obtaining diseases that start with k\n",
      " --> Obtaining diseases that start with l\n",
      " --> Obtaining diseases that start with m\n",
      " --> Obtaining diseases that start with n\n",
      " --> Obtaining diseases that start with o\n",
      " --> Obtaining diseases that start with p\n",
      " --> Obtaining diseases that start with q\n",
      " --> Obtaining diseases that start with r\n",
      " --> Obtaining diseases that start with s\n",
      " --> Obtaining diseases that start with t\n",
      " --> Obtaining diseases that start with u\n",
      " --> Obtaining diseases that start with v\n",
      " --> Obtaining diseases that start with w\n",
      " --> Obtaining diseases that start with x\n",
      " --> Obtaining diseases that start with y\n",
      " --> Obtaining diseases that start with z\n",
      "Total diseases:  490\n"
     ]
    }
   ],
   "source": [
    "# Obtains consolidated list of diseases (This step takes 8-10 mins to execute)\n",
    "\n",
    "print(\"\\n--------- OBTAINING LIST OF DISEASES ---------\\n\")\n",
    "diseases1 = getDiseasesFromNhp()\n",
    "diseases2 = getDiseasesFromPickle()\n",
    "all_diseases = getFinalDiseases(diseases1, diseases2)\n",
    "#print(all_diseases)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9174fb7-499a-42a4-8860-f9b2ec68604d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------- OBTAINING LIST OF SYMPTOMS ASSOCIATED WITH DISEASES ---------\n",
      "\n",
      "Processed  10  diseases\n",
      "Processed  20  diseases\n",
      "Processed  30  diseases\n",
      "Processed  40  diseases\n",
      "Processed  50  diseases\n",
      "Processed  60  diseases\n",
      "Processed  70  diseases\n",
      "Processed  80  diseases\n",
      "Processed  90  diseases\n",
      "Processed  100  diseases\n",
      "-------------------------------------\n",
      "Processed  110  diseases\n",
      "Processed  120  diseases\n",
      "Processed  130  diseases\n",
      "Processed  140  diseases\n",
      "Processed  150  diseases\n",
      "Processed  160  diseases\n",
      "Processed  170  diseases\n",
      "Processed  180  diseases\n",
      "Processed  190  diseases\n",
      "Processed  200  diseases\n",
      "-------------------------------------\n",
      "Processed  210  diseases\n",
      "Processed  220  diseases\n",
      "Processed  230  diseases\n",
      "Processed  240  diseases\n",
      "Processed  250  diseases\n",
      "Processed  260  diseases\n",
      "Processed  270  diseases\n",
      "Processed  280  diseases\n",
      "Processed  290  diseases\n",
      "Processed  300  diseases\n",
      "-------------------------------------\n",
      "Processed  310  diseases\n",
      "Processed  320  diseases\n",
      "Processed  330  diseases\n",
      "Processed  340  diseases\n",
      "Processed  350  diseases\n",
      "Processed  360  diseases\n",
      "Processed  370  diseases\n",
      "Processed  380  diseases\n",
      "Processed  390  diseases\n",
      "Processed  400  diseases\n",
      "-------------------------------------\n",
      "Processed  410  diseases\n",
      "Processed  420  diseases\n",
      "Processed  430  diseases\n",
      "Processed  440  diseases\n",
      "Processed  450  diseases\n",
      "Processed  460  diseases\n",
      "Processed  470  diseases\n",
      "Processed  480  diseases\n",
      "Processed  490  diseases\n",
      "Finished successfully !\n"
     ]
    }
   ],
   "source": [
    "# Obtains preprocessed list of symptoms associated with diseases (This step takes 25-30 mins to execute)\n",
    "\n",
    "print(\"\\n--------- OBTAINING LIST OF SYMPTOMS ASSOCIATED WITH DISEASES ---------\\n\")\n",
    "disease_symptoms = getSymptomsFromWiki(all_diseases)\n",
    "print(\"Finished successfully !\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "186a6ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total diseases considered after pre-processing:  292\n",
      "Diseases & Symptoms saved successfully !\n"
     ]
    }
   ],
   "source": [
    "# Saves the obtained result to the pickle file\n",
    "#print(disease_symptoms)\n",
    "\n",
    "saveSymptomsToPickle(disease_symptoms)\n",
    "print(\"Diseases & Symptoms saved successfully !\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
